---
title: 还好，这次没被封
tags: default
---



离爬取各种数据库已经差不多一年，又要更新一下了。以前爬[omim](https://pzweuj.github.io/2021/11/08/omim-crawler.html)数据库的时候，都会使用代理IP啥的，避免被封。但是最近学习了新的爬取姿势，目前运行了好几天了，还没被封IP，应该是目前体验较好的爬虫方式。

我将爬虫脚本全部从[selenium](https://www.selenium.dev/)或[requests](https://requests.readthedocs.io/en/latest/)改为了[playwright](https://playwright.dev/)。基本就是在模拟真实浏览器访问上越走越远。



使用selenium和playwright最大的特征是会被认为是webdriver，当网站识别是webdriver时，就会知道是爬虫。因此，这里有个解决方案（例子是selenium）是注入这段js来将webdriver值改为undefined。


```python
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
  "source": """
    Object.defineProperty(navigator, 'webdriver', {
      get: () => undefined
    })
  """
})
```



但是，在实测中（通过[这个网站](https://bot.sannysoft.com/)），这个方法无效。而目前使用的最有效的方法，是使用[stealth.min.js](https://github.com/requireCool/stealth.min.js)这个文件。



在打开页面前，先注入这个脚本即可。以下是playwright的例子。

```python
browser = playwright.chromium.launch(headless=True)
context = browser.new_context(
page = context.new_page()
# 注入脚本
page.add_init_script(path="stealth.min.js")
```



以下是selenium的例子

```python
driver = webdriver.Chrome()
with open("stealth.min.js", "r") as f:
    js = f.read()
driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {"source": js})
```

