---
title: 部署FLUX和Forge
tags: software
---

AI发展真的很快，一年多的时间，[Stable Diffusion](https://pzweuj.github.io/2023/03/26/Stable-Diffusion.html)的热度已被[FLUX](https://blackforestlabs.ai/#get-flux)打了下去。尝试一下现在的破电脑（RTX 2070，8G VRAM，16G RAM）能不能本地部署，感觉有点悬。不过可以找大佬优化了的模型进行部署。


## 安装Forge

首先安装[Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)这是Stable-Diffusion-webui的分支版本，支持FLUX的使用。

下载目前的[最新版本](https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z)，然后解压到合适的路径。

然后需要运行一次 update.bat进行初始化，升级和下载相关的依赖库。

然后就可以运行run.bat打开webui了。


## 部署FLUX

查了点资料，8GB 的显存可用的模型版本有NF4、GGUF、FP8等。因为我的显卡是20系，无法使用[NF4](https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4/tree/main)，可以使用[FP8](https://huggingface.co/XLabs-AI/flux-dev-fp8)，最后综合考虑使用[GGUF](https://huggingface.co/city96/FLUX.1-dev-gguf)。

根据[大佬的攻略](https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1050)，我下载了flux1-dev-Q4_K_S.gguf，然后需要放在webui/models/Stable-diffusion文件夹中。我打算如果跑不动，就用flux1-dev-Q3_K_S.gguf。

接下来还需要下载[VAE](https://huggingface.co/black-forest-labs/FLUX.1-dev/tree/main)，即ae.safetensors，放置在webui/models/VAE文件夹中。

最后下载[clip-l和t5](https://huggingface.co/comfyanonymous/flux_text_encoders/tree/main)，我下了clip_l.safetensors，但因为不知道下哪个t5好，所以我下了最小的那个，即t5xxl_fp8_e4m3fn.safetensors。需要放在webui/models/text_encoder文件夹中。


## 测试

看了一些视频资料，最后决定采用默认参数，不调整。测试了一下，跑得动！就是显卡和内存都快被拉爆了。出来的图比较模糊，我将采样次数改成了30，大概4分钟一幅图，偶尔跑跑还能接受。

接下来再下载一些LORA玩一下。

## 后续
AI迭代是真的快，这边刚部署好了FLUX，就听闻[Recraft V3（Red Panda）](https://www.recraft.ai)把FLUX比下来了，这个模型并不开源，但提供了在线的试用。









