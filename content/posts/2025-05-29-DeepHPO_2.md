---
title: DeepHPO更新了
tags: coding
---

时隔多月，对[DeepHPO](https://pzweuj.github.io/posts/DeepHPO)进行了更新。



## 知识库

首先是本次更新的重点。将原本就在项目中的HPO词表作为知识库，形成上下文投喂给deepseek，让输出的结果更准确。

这个功能在此前是使用腾讯的LKE平台实现的，但是没有实装到Vercel线上版本中。我本次尝试使用硅基流动提供的BGE-M3作为向量模型，将HPO词表向量化。

然而，向量化获得的词表，体积达到了200MB，由于Vercel的限制是100MB（应该是），这样就无法整个项目都塞在Vercel中了，必须要有另外一台服务器以后端API的方式提供，因此，转变思路。

（当然，在本地自部署我还是推荐使用RAG方案的）



## 拆词方案

本来考虑使用jieba等库，对患者表型进行拆词，但引入此库，对一个Vercel项目来说，可能又造成了负担。因此，又考虑先使用其他更轻量的语言模型进行拆词，然后将词语直接与HPO词表进行匹配，取相似度高的前几项作为上下文（是的，其实与向量化是相同的思路，不过没有向量化，效率相对低）。但是，这样可能会造成更高的token消耗。因此，我最后选择了更暴力的方案。



## 暴力拆词

对于英文，直接根据空格进行拆词；对于中文，采取2、3、4、5四种长度的滑窗拆词方式，将滑窗所得的所有词汇与HPO词表比较，获得相似度高的（更长的词汇优先）结果作为上下文。



-----------------------



**这样，在获得更多上下文后，DeepHPO现在输出的准确度提升明显。**[DeepHPO](https://deephpo.vercel.app/)现在也支持以OpenAI兼容的格式自行设置自己的AI提供商URL和模型了。欢迎大家使用。

