---
title: 2025总结
tags: default
---

**Merry Christmas! 🎄**

年底了，又到了年终总结的时间。



## 个人总结

今年我觉得是我与AI高度融合的一年，今年以来，我大量的个人行动和工作，都由AI指导。个人感觉效率极大的提升。

Github的Contributions可以侧面反映这个效率提升。2024年，我的总Contributions是487，而截止到2025年圣诞节，我的2025年Contributions是1507，**增幅**约209%。

工作上，由于经济下行，公司裁了大量的人，工作量都集中在少数人头上，我手上的杂事也是越来越多。但是，如我所说的，AI给了3倍的效率提升，因此实际我的摸鱼时间反而增加了（作为职场老油条，当然是不可能因为自己的效率提升然后问领导要更多的活的，工资又没有给我涨）。



## 展望2026

近期我密集调研了当前临床生产环境中的生信技术栈。作为一个负责搭建 Pipeline 的渣渣生信，我的核心目标只有两个：**极致的效率** 与 **极致的准确性**。

但我思考的是如何进行**工业化生产**，彻底摆脱传统手工作坊式的技术债。以下是我对未来（或者说现在）临床生信分析架构的深度复盘。

### 一、湿实验：用“标准”消灭“非标”

传统医检所最大的痛点是 SKU 过于繁杂。为了省一点测序费，搞了几十种不同大小的 Panel，导致建库流程支离破碎，人工成本居高不下。不做尖端研发和过多的产品，只做成熟的产品。

**必须做减法：锁定 SKU。**

只保留 **遗传全外显子 (WES)** 和 **肿瘤大 Panel (1000 Gene+)** 两条核心产线。

* **逻辑：** 虽然这砍掉了几十个基因的小 Panel，导致单个样本的测序试剂成本上升，但换来的是**建库流程的 100% 统一**。
* **收益：** 我们可以大规模采用自动化液体工作站，实现“黑灯工厂”式的生产。人工成本的降低和返工率的归零，完全可以覆盖多出来的测序成本。
* **速度：** 数据量增加了，分析速度自然下降，因此需要更强的机器，所以要上云。

这就像福特T型车：**“你可以选择任何颜色，只要它是黑色的。”** 标准化，是工业化的前提。

### 二、干实验：云边协同的混合架构

传统的“买几台服务器放在实验室隔壁”的模式已经过时了。我思考的新架构是：**数据重力在本地，算力爆发在云端。**

#### 1. 存储策略：存算分离与 CRAM 革命

所有原始数据（FastQ）产生于本地，保留在本地存储中（或定期冷备份），不轻易上云，以节省昂贵的上传带宽和存储费。

而分析产生的中间文件，必须对行业惯例动刀：

* **再见，BAM：** 传统的 BAM 文件动辄几 GB，不仅贵而且慢。
* **你好，CRAM：** 全面转向 CRAM 格式。基于参考基因组的差量压缩，能让存储体积缩小 **50%**。
* **结构化数据：** 所有的 VCF 注释结果、QC 报告，不再是散乱的文本，而是被清洗为 **Apache Parquet** 格式。这是一种列式存储格式，极小、极快，为下游分析做好了准备。
**生命周期管理：**  CRAM、VCF数据在 S3 桶中保存 5 年，到期自动触发销毁策略。这不再需要人工运维，而是代码定义的规则。

#### 2. 算力账本：买不买服务器

Gemini 曾帮我算过一笔账，这也是我认为 All-in Cloud 可行的原因：

1. **总预算 (TCO):** 200 万人民币。
2. **时间跨度:** 5 年。
3. **任务模型:** WES 分析 (10GB FastQ)，标准流程 (Spot + CRAM)。
4. **关键修正:**
* **本地:** 必须包含电费、运维费、配件更换费。
* **云端:** 必须包含**网络带宽费**（解决上传瓶颈）、存储费、以及 API 请求费。


| 维度 | 方案 A：本地集群 (200万) | 方案 B：云端 (200万) |
| --- | --- | --- |
| **5 年最大产能** | **3,000,000+** (上限极高) | **~136,000** (钱花完就停) |
| **固定资产投入** | **130 万** (第一天就花掉) | **0** |
| **第 1 年产能** | 闲置 (如果样本少) | 精准匹配 |
| **第 5 年资产价值** | < 10 万 (电子垃圾) | 0 |
| **盈亏平衡点** | **约 15 万个样本** | N/A (线性成本) |

##### 决策逻辑

**“赌量”还是“赌命”？**

1. **如果你是华大基因 (BGI)：** 你每年确定有 100 万个样本。**必须选 A (本地)**。因为选 A，单样本成本会被摊薄到 **0.7 元**；选 B 永远是 11 元。
2. **如果你是小公司：** 我们是一家初创公司。
* 如果选 A，开局就要烧掉 130 万现金。如果前两年只接了 2 万个单子，单样本成本高达 **100 元** (130万/2万+电费)，且现金流枯竭，公司会死。
* 如果选 B，前两年接 2 万个单子，只花了 22 万。手里还有 178 万现金活着。

**结论：**
**本地方案是“省钱”的终点，但在没达到 15 万样本量之前，它是“烧钱”的黑洞。**
云端方案虽然单价贵，但它是**活下去的资格**。

### 三、可视化系统：边缘计算的胜利

很多同行的系统卡顿，是因为还在用 MySQL 去硬抗几万个突变位点的查询。

可视化分析系统采用了 **Parquet + DuckDB (WASM)** 的边缘计算架构：

1. **后端 0 压力：** 用户打开报告时，浏览器自动下载该样本的 Parquet 文件（仅十几 MB）。
2. **前端极速计算：** 所有的筛选、排序、复合查询，全部由用户浏览器里的 DuckDB 引擎完成。响应速度是毫秒级的。
3. **流式读取 CRAM：** 当医生需要查看 IGV 时，前端通过 S3 预签名链接 (Signed URL) 直接读取云端的 CRAM 片段。数据不经过我们的后端服务器，流量成本再次降低。

这是真正的**“零数据库成本”**架构。

### 四、后端引擎：Nextflow + K8s

既然定位是工业级，就不要再用 Old School 的 PBS/Slurm 投递任务了，也不要用 singularity 去手动管理环境。

* **流程引擎：** 全面拥抱 **Nextflow**。它的容错机制（自动重试 Spot 实例被抢占的任务）和模块化设计是云原生的绝配。
* **调度系统：** 使用 **Kubernetes (K8s)**。它是现代基础设施的标准。
* **容器化：** 所有模块（从 bwa 到 gatk）全部 Docker 化。

这套架构做到了**“一次编写，到处运行”**。无论是阿里云、AWS，还是本地的一台测试机，只要有 Docker，流程就能跑通。



## 做点什么

2026年，我预估会产出一套开源的全外显子可视化分析系统、一套开源的肿瘤靶向用药可视化分析系统。


2025个人年度歌，王力宏的我们的歌。

[qqmusic:102193483]
